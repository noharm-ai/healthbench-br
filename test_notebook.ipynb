{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# HealthBench-BR - Teste com 20 Primeiras Perguntas\n",
    "\n",
    "Este notebook testa os modelos ativos configurados em `providers.json` usando as primeiras 20 perguntas do dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üîç Vari√°veis carregadas do .env:\n",
      "   AWS_ACCESS_KEY_ID = ‚ùå N√£o definida\n",
      "   AWS_SECRET_ACCESS_KEY = ‚ùå N√£o definida\n",
      "   AWS_DEFAULT_REGION = ‚ùå N√£o definida\n",
      "   AWS_BEARER_TOKEN_BEDROCK = ABSK...\n",
      "   OPENAI_API_KEY = ‚ùå N√£o definida\n",
      "   MARITACA_API_KEY = 1000...\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import os\n",
    "import sys\n",
    "import asyncio\n",
    "from typing import List, Dict\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# Carrega vari√°veis do .env sobrescrevendo as j√° existentes\n",
    "load_dotenv(override=True)\n",
    "\n",
    "# üîç Debug: imprime vari√°veis sens√≠veis carregadas (s√≥ nomes, n√£o valores)\n",
    "print(\"\\nüîç Vari√°veis carregadas do .env:\")\n",
    "for key in [\"AWS_ACCESS_KEY_ID\", \"AWS_SECRET_ACCESS_KEY\", \"AWS_DEFAULT_REGION\", \n",
    "            \"AWS_BEARER_TOKEN_BEDROCK\", \"OPENAI_API_KEY\", \"MARITACA_API_KEY\"]:\n",
    "    value = os.getenv(key)\n",
    "    if value:\n",
    "        masked = value[:4] + \"...\" if len(value) > 8 else \"***\"\n",
    "        print(f\"   {key} = {masked}\")\n",
    "    else:\n",
    "        print(f\"   {key} = ‚ùå N√£o definida\")\n",
    "\n",
    "# Add src to path\n",
    "sys.path.insert(0, os.path.dirname(os.path.abspath('.')))\n",
    "\n",
    "from src.providers.base import ProviderConfig\n",
    "from src.providers.factory import ProviderFactory\n",
    "from src.dataset.loader import DatasetLoader\n",
    "from src.evaluation.evaluator import Evaluator\n",
    "from src.reports.generator import ReportGenerator, EvaluationResult"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Configura√ß√£o dos Providers\n",
    "\n",
    "Carregamos os providers ativos do arquivo `providers.json`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Providers candidatos encontrados: 3\n",
      "\n",
      "üîç Validando MedGemma-27B-Q8 (ollama: jwang580/medgemma_27b_q8_0:latest)...\n",
      "      ‚úÖ Ollama est√° executando em http://localhost:11434\n",
      "      ‚úÖ Modelo jwang580/medgemma_27b_q8_0:latest est√° dispon√≠vel\n",
      "   ‚úÖ MedGemma-27B-Q8 - Configura√ß√£o v√°lida\n",
      "\n",
      "üîç Validando Claude-Sonnet-4-Bedrock (aws_bedrock: global.anthropic.claude-sonnet-4-20250514-v1:0)...\n",
      "      ‚úÖ Vari√°vel de ambiente AWS_BEARER_TOKEN_BEDROCK encontrada\n",
      "      ‚úÖ Bearer token configurado para Bedrock\n",
      "   ‚úÖ Claude-Sonnet-4-Bedrock - Configura√ß√£o v√°lida\n",
      "\n",
      "üîç Validando Maritaca-Sabiazinho-3 (maritaca: sabiazinho-3)...\n",
      "      ‚úÖ Vari√°vel de ambiente MARITACA_API_KEY encontrada\n",
      "      ‚úÖ Conectividade com Maritaca OK\n",
      "   ‚úÖ Maritaca-Sabiazinho-3 - Configura√ß√£o v√°lida\n",
      "\n",
      "üìä Resumo da valida√ß√£o:\n",
      "   Providers candidatos: 3\n",
      "   Providers v√°lidos: 3\n",
      "\n",
      "‚úÖ Providers prontos para teste:\n",
      "   - MedGemma-27B-Q8 (ollama: jwang580/medgemma_27b_q8_0:latest)\n",
      "   - Claude-Sonnet-4-Bedrock (aws_bedrock: global.anthropic.claude-sonnet-4-20250514-v1:0)\n",
      "   - Maritaca-Sabiazinho-3 (maritaca: sabiazinho-3)\n"
     ]
    }
   ],
   "source": [
    "def load_active_providers(providers_file: str = \"providers.json\") -> List[Dict]:\n",
    "    \"\"\"Load active providers from JSON configuration file with environment and connectivity checks\"\"\"\n",
    "    with open(providers_file, 'r', encoding='utf-8') as f:\n",
    "        config = json.load(f)\n",
    "    \n",
    "    # Filter only active providers\n",
    "    candidate_providers = [p for p in config['providers'] if p.get('active', False)]\n",
    "    \n",
    "    print(f\"Providers candidatos encontrados: {len(candidate_providers)}\")\n",
    "    \n",
    "    validated_providers = []\n",
    "    \n",
    "    for provider in candidate_providers:\n",
    "        print(f\"\\nüîç Validando {provider['name']} ({provider['type']}: {provider['model']})...\")\n",
    "        \n",
    "        # Check environment variables and connectivity\n",
    "        is_valid = validate_provider_config(provider)\n",
    "        \n",
    "        if is_valid:\n",
    "            validated_providers.append(provider)\n",
    "            print(f\"   ‚úÖ {provider['name']} - Configura√ß√£o v√°lida\")\n",
    "        else:\n",
    "            print(f\"   ‚ùå {provider['name']} - Configura√ß√£o inv√°lida (ser√° ignorado)\")\n",
    "    \n",
    "    print(f\"\\nüìä Resumo da valida√ß√£o:\")\n",
    "    print(f\"   Providers candidatos: {len(candidate_providers)}\")\n",
    "    print(f\"   Providers v√°lidos: {len(validated_providers)}\")\n",
    "    \n",
    "    if validated_providers:\n",
    "        print(f\"\\n‚úÖ Providers prontos para teste:\")\n",
    "        for provider in validated_providers:\n",
    "            print(f\"   - {provider['name']} ({provider['type']}: {provider['model']})\")\n",
    "    \n",
    "    return validated_providers, config['default_settings']\n",
    "\n",
    "\n",
    "def validate_provider_config(provider: Dict) -> bool:\n",
    "    \"\"\"Validate provider configuration including environment variables and connectivity\"\"\"\n",
    "    provider_type = provider['type']\n",
    "    \n",
    "    try:\n",
    "        # Check environment variables based on provider type\n",
    "        if provider_type == 'openai':\n",
    "            return validate_openai_config(provider)\n",
    "        elif provider_type == 'maritaca':\n",
    "            return validate_maritaca_config(provider)\n",
    "        elif provider_type == 'ollama':\n",
    "            return validate_ollama_config(provider)\n",
    "        elif provider_type == 'aws_bedrock':\n",
    "            return validate_bedrock_config(provider)\n",
    "        else:\n",
    "            print(f\"      ‚ö†Ô∏è Tipo de provider desconhecido: {provider_type}\")\n",
    "            return False\n",
    "            \n",
    "    except Exception as e:\n",
    "        print(f\"      ‚ùå Erro na valida√ß√£o: {e}\")\n",
    "        return False\n",
    "\n",
    "\n",
    "def validate_openai_config(provider: Dict) -> bool:\n",
    "    \"\"\"Validate OpenAI provider configuration\"\"\"\n",
    "    api_key = provider.get('api_key', '')\n",
    "    \n",
    "    # Resolve environment variable\n",
    "    if api_key.startswith('${') and api_key.endswith('}'):\n",
    "        env_var = api_key[2:-1]\n",
    "        actual_key = os.getenv(env_var)\n",
    "        if not actual_key:\n",
    "            print(f\"      ‚ùå Vari√°vel de ambiente {env_var} n√£o encontrada\")\n",
    "            return False\n",
    "        print(f\"      ‚úÖ Vari√°vel de ambiente {env_var} encontrada\")\n",
    "    elif not api_key:\n",
    "        print(f\"      ‚ùå API key n√£o configurada\")\n",
    "        return False\n",
    "    \n",
    "    # Test connectivity (simple check)\n",
    "    base_url = provider.get('base_url', 'https://api.openai.com')\n",
    "    try:\n",
    "        import requests\n",
    "        response = requests.get(f\"{base_url}/v1/models\", timeout=10, headers={\n",
    "            'Authorization': f\"Bearer {actual_key if 'actual_key' in locals() else 'test'}\"\n",
    "        })\n",
    "        if response.status_code in [200, 401]:  # 401 means auth failed but service is reachable\n",
    "            print(f\"      ‚úÖ Conectividade com OpenAI OK\")\n",
    "            return True\n",
    "        else:\n",
    "            print(f\"      ‚ö†Ô∏è Resposta inesperada da API: {response.status_code}\")\n",
    "            return False\n",
    "    except Exception as e:\n",
    "        print(f\"      ‚ö†Ô∏è N√£o foi poss√≠vel testar conectividade: {e}\")\n",
    "        return True  # Allow to proceed anyway\n",
    "\n",
    "\n",
    "def validate_maritaca_config(provider: Dict) -> bool:\n",
    "    \"\"\"Validate Maritaca provider configuration\"\"\"\n",
    "    api_key = provider.get('api_key', '')\n",
    "    \n",
    "    # Resolve environment variable\n",
    "    if api_key.startswith('${') and api_key.endswith('}'):\n",
    "        env_var = api_key[2:-1]\n",
    "        actual_key = os.getenv(env_var)\n",
    "        if not actual_key:\n",
    "            print(f\"      ‚ùå Vari√°vel de ambiente {env_var} n√£o encontrada\")\n",
    "            return False\n",
    "        print(f\"      ‚úÖ Vari√°vel de ambiente {env_var} encontrada\")\n",
    "    elif not api_key:\n",
    "        print(f\"      ‚ùå API key n√£o configurada\")\n",
    "        return False\n",
    "    \n",
    "    # Test connectivity\n",
    "    base_url = provider.get('base_url', 'https://chat.maritaca.ai')\n",
    "    try:\n",
    "        import requests\n",
    "        response = requests.get(base_url, timeout=10)\n",
    "        if response.status_code == 200:\n",
    "            print(f\"      ‚úÖ Conectividade com Maritaca OK\")\n",
    "            return True\n",
    "        else:\n",
    "            print(f\"      ‚ö†Ô∏è Resposta inesperada: {response.status_code}\")\n",
    "            return False\n",
    "    except Exception as e:\n",
    "        print(f\"      ‚ö†Ô∏è N√£o foi poss√≠vel testar conectividade: {e}\")\n",
    "        return True  # Allow to proceed anyway\n",
    "\n",
    "\n",
    "def validate_ollama_config(provider: Dict) -> bool:\n",
    "    \"\"\"Validate Ollama provider configuration\"\"\"\n",
    "    base_url = provider.get('base_url', 'http://localhost:11434')\n",
    "    model = provider.get('model')\n",
    "    \n",
    "    # Test if Ollama is running\n",
    "    try:\n",
    "        import requests\n",
    "        response = requests.get(f\"{base_url}/api/tags\", timeout=10)\n",
    "        if response.status_code == 200:\n",
    "            print(f\"      ‚úÖ Ollama est√° executando em {base_url}\")\n",
    "            \n",
    "            # Check if model is available\n",
    "            models = response.json()\n",
    "            available_models = [m['name'] for m in models.get('models', [])]\n",
    "            \n",
    "            if model in available_models:\n",
    "                print(f\"      ‚úÖ Modelo {model} est√° dispon√≠vel\")\n",
    "                return True\n",
    "            else:\n",
    "                print(f\"      ‚ùå Modelo {model} n√£o encontrado\")\n",
    "                print(f\"      üí° Modelos dispon√≠veis: {available_models[:3]}{'...' if len(available_models) > 3 else ''}\")\n",
    "                return False\n",
    "        else:\n",
    "            print(f\"      ‚ùå Ollama n√£o est√° respondendo (c√≥digo {response.status_code})\")\n",
    "            return False\n",
    "    except Exception as e:\n",
    "        print(f\"      ‚ùå Erro ao conectar com Ollama: {e}\")\n",
    "        print(f\"      üí° Verifique se Ollama est√° executando em {base_url}\")\n",
    "        return False\n",
    "\n",
    "\n",
    "def validate_bedrock_config(provider: Dict) -> bool:\n",
    "    \"\"\"Validate AWS Bedrock provider configuration\"\"\"\n",
    "    bearer_token = provider.get('aws_bearer_token', '')\n",
    "    region = provider.get('region', 'us-east-1')\n",
    "    \n",
    "    # Check bearer token environment variable\n",
    "    if bearer_token.startswith('${') and bearer_token.endswith('}'):\n",
    "        env_var = bearer_token[2:-1]\n",
    "        actual_token = os.getenv(env_var)\n",
    "        if not actual_token:\n",
    "            print(f\"      ‚ùå Vari√°vel de ambiente {env_var} n√£o encontrada\")\n",
    "            return False\n",
    "        print(f\"      ‚úÖ Vari√°vel de ambiente {env_var} encontrada\")\n",
    "\n",
    "        # Se o bearer token existe, j√° √© suficiente\n",
    "        os.environ['AWS_BEARER_TOKEN_BEDROCK'] = actual_token\n",
    "        print(f\"      ‚úÖ Bearer token configurado para Bedrock\")\n",
    "        return True   # ‚Üê retorno antecipado se token est√° ok\n",
    "    \n",
    "    # Caso n√£o exista bearer token, verifica credenciais tradicionais\n",
    "    aws_access_key = os.getenv('AWS_ACCESS_KEY_ID')\n",
    "    aws_secret_key = os.getenv('AWS_SECRET_ACCESS_KEY')\n",
    "    \n",
    "    if not aws_access_key and not aws_secret_key:\n",
    "        print(f\"      ‚ö†Ô∏è Credenciais AWS n√£o encontradas no ambiente\")\n",
    "        print(f\"      üí° Tentando usar perfil padr√£o AWS...\")\n",
    "        \n",
    "        try:\n",
    "            import boto3\n",
    "            session = boto3.Session()\n",
    "            credentials = session.get_credentials()\n",
    "            if credentials:\n",
    "                print(f\"      ‚úÖ Credenciais AWS encontradas no perfil\")\n",
    "                return True\n",
    "            else:\n",
    "                print(f\"      ‚ùå Nenhuma credencial AWS dispon√≠vel\")\n",
    "                return False\n",
    "        except Exception as e:\n",
    "            print(f\"      ‚ùå Erro ao verificar credenciais AWS: {e}\")\n",
    "            return False\n",
    "    else:\n",
    "        print(f\"      ‚úÖ Credenciais AWS encontradas no ambiente\")\n",
    "        return True\n",
    "\n",
    "\n",
    "# Load providers with validation\n",
    "active_providers, default_settings = load_active_providers()\n",
    "\n",
    "if not active_providers:\n",
    "    raise ValueError(\"\\n‚ùå Nenhum provider v√°lido encontrado!\\n\\n\" +\n",
    "                    \"üí° Poss√≠veis solu√ß√µes:\\n\" +\n",
    "                    \"   1. Verifique as vari√°veis de ambiente necess√°rias\\n\" +\n",
    "                    \"   2. Certifique-se de que o Ollama est√° executando (se aplic√°vel)\\n\" +\n",
    "                    \"   3. Configure as credenciais AWS (se aplic√°vel)\\n\" +\n",
    "                    \"   4. Verifique as configura√ß√µes em providers.json\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Carregamento do Dataset\n",
    "\n",
    "Carregamos apenas as primeiras 20 perguntas do dataset para teste."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Carregando dataset...\n",
      "Dataset carregado: 20 perguntas (primeiras 20)\n",
      "Arquivos √∫nicos: 2\n",
      "T√≠tulos √∫nicos: 2\n",
      "\n",
      "Exemplo de perguntas:\n",
      "\n",
      "1. [V_PCDT_-_Vasculite__-_Atualizado.pdf] Protocolo cl√≠nico e diretrizes terap√™uticas da vasculite associada aos anticorpos anti-citoplasma de neutr√≥filos\n",
      "   Pergunta: No que diz respeito ao protocolo cl√≠nico \"Protocolo Cl√≠nico e Diretrizes Terap√™uticas da Vasculite A...\n",
      "   Resposta esperada: Verdadeiro\n",
      "\n",
      "2. [V_PCDT_-_Vasculite__-_Atualizado.pdf] Protocolo cl√≠nico e diretrizes terap√™uticas da vasculite associada aos anticorpos anti-citoplasma de neutr√≥filos\n",
      "   Pergunta: No que diz respeito ao protocolo cl√≠nico \"Protocolo Cl√≠nico e Diretrizes Terap√™uticas da Vasculite A...\n",
      "   Resposta esperada: Falso\n",
      "\n",
      "3. [V_PCDT_-_Vasculite__-_Atualizado.pdf] Protocolo cl√≠nico e diretrizes terap√™uticas da vasculite associada aos anticorpos anti-citoplasma de neutr√≥filos\n",
      "   Pergunta: No que diz respeito ao protocolo cl√≠nico \"Protocolo Cl√≠nico e Diretrizes Terap√™uticas da Vasculite A...\n",
      "   Resposta esperada: Verdadeiro\n"
     ]
    }
   ],
   "source": [
    "# Load dataset (first 20 questions)\n",
    "print(\"Carregando dataset...\")\n",
    "dataset = DatasetLoader.load_dataset(\"benchmark_perguntas_unificado.json\")\n",
    "test_dataset = dataset[:20]  # Only first 20 questions\n",
    "\n",
    "print(f\"Dataset carregado: {len(test_dataset)} perguntas (primeiras 20)\")\n",
    "print(f\"Arquivos √∫nicos: {len(set(q.arquivo for q in test_dataset))}\")\n",
    "print(f\"T√≠tulos √∫nicos: {len(set(q.titulo for q in test_dataset))}\")\n",
    "\n",
    "# Show sample questions\n",
    "print(\"\\nExemplo de perguntas:\")\n",
    "for i, question in enumerate(test_dataset[:3]):\n",
    "    print(f\"\\n{i+1}. [{question.arquivo}] {question.titulo}\")\n",
    "    print(f\"   Pergunta: {question.pergunta[:100]}...\")\n",
    "    print(f\"   Resposta esperada: {question.esperado}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fun√ß√£o para Criar Providers\n",
    "\n",
    "Fun√ß√£o auxiliar para instanciar providers baseado na configura√ß√£o."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fun√ß√£o create_provider_from_config definida.\n"
     ]
    }
   ],
   "source": [
    "def create_provider_from_config(provider_config: Dict):\n",
    "    \"\"\"Create a provider instance from configuration\"\"\"\n",
    "    from src.providers.maritaca import MaritacaProvider\n",
    "    from src.providers.openai_provider import OpenAIProvider\n",
    "    from src.providers.ollama import OllamaProvider\n",
    "    from src.providers.bedrock import BedrockProvider\n",
    "    \n",
    "    # Create base config\n",
    "    config = ProviderConfig(\n",
    "        model_name=provider_config['model'],\n",
    "        temperature=provider_config.get('temperature', 0.0),\n",
    "        max_tokens=provider_config.get('max_tokens', 12000),\n",
    "        api_key=provider_config.get('api_key'),\n",
    "        base_url=provider_config.get('base_url'),\n",
    "        timeout=provider_config.get('timeout', 120)\n",
    "    )\n",
    "    \n",
    "    # Create provider based on type\n",
    "    provider_type = provider_config['type']\n",
    "    \n",
    "    if provider_type == 'maritaca':\n",
    "        return MaritacaProvider(config)\n",
    "    elif provider_type == 'openai':\n",
    "        return OpenAIProvider(config)\n",
    "    elif provider_type == 'ollama':\n",
    "        return OllamaProvider(config)\n",
    "    elif provider_type == 'aws_bedrock':\n",
    "        return BedrockProvider(\n",
    "            config,\n",
    "            region_name=provider_config.get('region', 'us-east-1'),\n",
    "            aws_bearer_token=provider_config.get('aws_bearer_token')\n",
    "        )\n",
    "    else:\n",
    "        raise ValueError(f\"Tipo de provider n√£o suportado: {provider_type}\")\n",
    "\n",
    "print(\"Fun√ß√£o create_provider_from_config definida.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Execu√ß√£o dos Testes\n",
    "\n",
    "Executamos a avalia√ß√£o para cada provider ativo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fun√ß√£o run_evaluation_for_provider definida.\n"
     ]
    }
   ],
   "source": [
    "async def run_evaluation_for_provider(provider_config: Dict, dataset: List, parallelism: int = 3):\n",
    "    \"\"\"Run evaluation for a single provider\"\"\"\n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(f\"Testando: {provider_config['name']} ({provider_config['model']})\")\n",
    "    print(f\"{'='*60}\")\n",
    "    \n",
    "    try:\n",
    "        # Create provider\n",
    "        provider = create_provider_from_config(provider_config)\n",
    "        \n",
    "        # Create evaluator with reduced parallelism for testing\n",
    "        evaluator = Evaluator(provider, parallelism=parallelism)\n",
    "        \n",
    "        # Run evaluation\n",
    "        start_time = datetime.now()\n",
    "        results = await evaluator.evaluate(dataset, show_progress=True)\n",
    "        end_time = datetime.now()\n",
    "        \n",
    "        # Calculate metrics\n",
    "        total = len(results)\n",
    "        correct = sum(1 for r in results if r.correta)\n",
    "        accuracy = correct / total if total > 0 else 0\n",
    "        duration = (end_time - start_time).total_seconds()\n",
    "        \n",
    "        print(f\"\\nüìä Resultados para {provider_config['name']}:\")\n",
    "        print(f\"   Total de perguntas: {total}\")\n",
    "        print(f\"   Acertos: {correct}\")\n",
    "        print(f\"   Acur√°cia: {accuracy:.2%}\")\n",
    "        print(f\"   Tempo: {duration:.1f}s\")\n",
    "        \n",
    "        return {\n",
    "            'provider_name': provider_config['name'],\n",
    "            'provider_type': provider_config['type'],\n",
    "            'model': provider_config['model'],\n",
    "            'total': total,\n",
    "            'correct': correct,\n",
    "            'accuracy': accuracy,\n",
    "            'duration_seconds': duration,\n",
    "            'results': results\n",
    "        }\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Erro ao testar {provider_config['name']}: {e}\")\n",
    "        import traceback\n",
    "        traceback.print_exc()\n",
    "        return None\n",
    "\n",
    "print(\"Fun√ß√£o run_evaluation_for_provider definida.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Execu√ß√£o dos Testes para Todos os Providers Ativos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "Testando: MedGemma-27B-Q8 (jwang580/medgemma_27b_q8_0:latest)\n",
      "============================================================\n",
      "Total de perguntas a avaliar: 20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batch 1:   0%|                                                                                        | 0/3 [00:00<?, ?it/s]/Users/filipelopes/Desktop/Development/notebooks/noharm-maritaca/healthbench-br/src/providers/ollama.py:16: LangChainDeprecationWarning: The class `Ollama` was deprecated in LangChain 0.3.1 and will be removed in 1.0.0. An updated version of the class exists in the :class:`~langchain-ollama package and should be used instead. To use it run `pip install -U :class:`~langchain-ollama` and import as `from :class:`~langchain_ollama import OllamaLLM``.\n",
      "  return Ollama(\n",
      "Batch 1: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 3/3 [01:09<00:00, 23.17s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Acur√°cia parcial: 2/3 = 0.667\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batch 2: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 3/3 [00:41<00:00, 13.93s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Acur√°cia parcial: 3/6 = 0.500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batch 3: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 3/3 [00:33<00:00, 11.15s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Acur√°cia parcial: 6/9 = 0.667\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batch 4: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 3/3 [00:26<00:00,  8.79s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Acur√°cia parcial: 8/12 = 0.667\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batch 5: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 3/3 [00:49<00:00, 16.51s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Acur√°cia parcial: 10/15 = 0.667\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batch 6: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 3/3 [00:42<00:00, 14.17s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Acur√°cia parcial: 11/18 = 0.611\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batch 7: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2/2 [00:43<00:00, 21.77s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Acur√°cia parcial: 12/20 = 0.600\n",
      "\n",
      "üìä Resultados para MedGemma-27B-Q8:\n",
      "   Total de perguntas: 20\n",
      "   Acertos: 12\n",
      "   Acur√°cia: 60.00%\n",
      "   Tempo: 306.9s\n",
      "\n",
      "============================================================\n",
      "Testando: Claude-Sonnet-4-Bedrock (global.anthropic.claude-sonnet-4-20250514-v1:0)\n",
      "============================================================\n",
      "Total de perguntas a avaliar: 20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batch 1: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 3/3 [00:01<00:00,  1.74it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Acur√°cia parcial: 0/3 = 0.000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batch 2: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 3/3 [00:00<00:00, 18.60it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Acur√°cia parcial: 0/6 = 0.000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batch 3: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 3/3 [00:00<00:00, 17.12it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Acur√°cia parcial: 0/9 = 0.000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batch 4: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 3/3 [00:00<00:00, 17.68it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Acur√°cia parcial: 0/12 = 0.000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batch 5: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 3/3 [00:00<00:00, 37.69it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Acur√°cia parcial: 0/15 = 0.000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batch 6: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 3/3 [00:00<00:00, 17.68it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Acur√°cia parcial: 0/18 = 0.000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batch 7: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2/2 [00:00<00:00, 13.86it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Acur√°cia parcial: 0/20 = 0.000\n",
      "\n",
      "üìä Resultados para Claude-Sonnet-4-Bedrock:\n",
      "   Total de perguntas: 20\n",
      "   Acertos: 0\n",
      "   Acur√°cia: 0.00%\n",
      "   Tempo: 2.6s\n",
      "\n",
      "============================================================\n",
      "Testando: Maritaca-Sabiazinho-3 (sabiazinho-3)\n",
      "============================================================\n",
      "Total de perguntas a avaliar: 20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batch 1: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 3/3 [00:00<00:00,  4.85it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Acur√°cia parcial: 0/3 = 0.000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batch 2: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 3/3 [00:00<00:00, 21.69it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Acur√°cia parcial: 0/6 = 0.000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batch 3: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 3/3 [00:00<00:00, 22.27it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Acur√°cia parcial: 0/9 = 0.000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batch 4: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 3/3 [00:00<00:00, 22.51it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Acur√°cia parcial: 0/12 = 0.000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batch 5: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 3/3 [00:00<00:00, 21.85it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Acur√°cia parcial: 0/15 = 0.000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batch 6: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 3/3 [00:00<00:00, 21.13it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Acur√°cia parcial: 0/18 = 0.000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batch 7: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2/2 [00:00<00:00, 14.21it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Acur√°cia parcial: 0/20 = 0.000\n",
      "\n",
      "üìä Resultados para Maritaca-Sabiazinho-3:\n",
      "   Total de perguntas: 20\n",
      "   Acertos: 0\n",
      "   Acur√°cia: 0.00%\n",
      "   Tempo: 1.5s\n",
      "\n",
      "üéâ Testes conclu√≠dos! 3 providers testados com sucesso.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Run tests for all active providers\n",
    "all_results = []\n",
    "\n",
    "for provider_config in active_providers:\n",
    "    result = await run_evaluation_for_provider(provider_config, test_dataset, parallelism=3)\n",
    "    if result:\n",
    "        all_results.append(result)\n",
    "\n",
    "print(f\"\\nüéâ Testes conclu√≠dos! {len(all_results)} providers testados com sucesso.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compara√ß√£o de Resultados\n",
    "\n",
    "Visualizamos uma tabela comparativa dos resultados."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìã COMPARA√á√ÉO DE RESULTADOS\n",
      "================================================================================\n",
      "               Provider        Tipo                                         Modelo  Total  Acertos Acur√°cia Tempo (s)\n",
      "        MedGemma-27B-Q8      ollama              jwang580/medgemma_27b_q8_0:latest     20       12   60.00%     306.9\n",
      "Claude-Sonnet-4-Bedrock aws_bedrock global.anthropic.claude-sonnet-4-20250514-v1:0     20        0    0.00%       2.6\n",
      "  Maritaca-Sabiazinho-3    maritaca                                   sabiazinho-3     20        0    0.00%       1.5\n",
      "\n",
      "üèÜ Melhor desempenho: MedGemma-27B-Q8 com 60.00% de acur√°cia\n"
     ]
    }
   ],
   "source": [
    "if all_results:\n",
    "    # Create comparison DataFrame\n",
    "    comparison_data = []\n",
    "    for result in all_results:\n",
    "        comparison_data.append({\n",
    "            'Provider': result['provider_name'],\n",
    "            'Tipo': result['provider_type'],\n",
    "            'Modelo': result['model'],\n",
    "            'Total': result['total'],\n",
    "            'Acertos': result['correct'],\n",
    "            'Acur√°cia': f\"{result['accuracy']:.2%}\",\n",
    "            'Tempo (s)': f\"{result['duration_seconds']:.1f}\"\n",
    "        })\n",
    "    \n",
    "    comparison_df = pd.DataFrame(comparison_data)\n",
    "    \n",
    "    print(\"üìã COMPARA√á√ÉO DE RESULTADOS\")\n",
    "    print(\"=\" * 80)\n",
    "    print(comparison_df.to_string(index=False))\n",
    "    \n",
    "    # Find best performer\n",
    "    best_result = max(all_results, key=lambda x: x['accuracy'])\n",
    "    print(f\"\\nüèÜ Melhor desempenho: {best_result['provider_name']} com {best_result['accuracy']:.2%} de acur√°cia\")\n",
    "else:\n",
    "    print(\"‚ùå Nenhum resultado v√°lido para comparar.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gera√ß√£o de Relat√≥rios Detalhados\n",
    "\n",
    "Geramos relat√≥rios CSV e HTML para cada provider testado."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CSV salvo em: /Users/filipelopes/Desktop/Development/notebooks/noharm-maritaca/healthbench-br/test_results_MedGemma_27B_Q8_20251004_073005.csv\n",
      "Relat√≥rio HTML salvo em: /Users/filipelopes/Desktop/Development/notebooks/noharm-maritaca/healthbench-br/test_results_MedGemma_27B_Q8_20251004_073005_report.html\n",
      "üìÑ Relat√≥rios gerados para MedGemma-27B-Q8:\n",
      "   CSV: test_results_MedGemma_27B_Q8_20251004_073005.csv\n",
      "   HTML: test_results_MedGemma_27B_Q8_20251004_073005_report.html\n",
      "CSV salvo em: /Users/filipelopes/Desktop/Development/notebooks/noharm-maritaca/healthbench-br/test_results_Claude_Sonnet_4_Bedrock_20251004_073005.csv\n",
      "Relat√≥rio HTML salvo em: /Users/filipelopes/Desktop/Development/notebooks/noharm-maritaca/healthbench-br/test_results_Claude_Sonnet_4_Bedrock_20251004_073005_report.html\n",
      "üìÑ Relat√≥rios gerados para Claude-Sonnet-4-Bedrock:\n",
      "   CSV: test_results_Claude_Sonnet_4_Bedrock_20251004_073005.csv\n",
      "   HTML: test_results_Claude_Sonnet_4_Bedrock_20251004_073005_report.html\n",
      "CSV salvo em: /Users/filipelopes/Desktop/Development/notebooks/noharm-maritaca/healthbench-br/test_results_Maritaca_Sabiazinho_3_20251004_073005.csv\n",
      "Relat√≥rio HTML salvo em: /Users/filipelopes/Desktop/Development/notebooks/noharm-maritaca/healthbench-br/test_results_Maritaca_Sabiazinho_3_20251004_073005_report.html\n",
      "üìÑ Relat√≥rios gerados para Maritaca-Sabiazinho-3:\n",
      "   CSV: test_results_Maritaca_Sabiazinho_3_20251004_073005.csv\n",
      "   HTML: test_results_Maritaca_Sabiazinho_3_20251004_073005_report.html\n",
      "\n",
      "‚úÖ Todos os relat√≥rios foram gerados com sucesso!\n"
     ]
    }
   ],
   "source": [
    "# Generate detailed reports for each provider\n",
    "for result in all_results:\n",
    "    provider_name = result['provider_name'].replace(' ', '_').replace('-', '_')\n",
    "    timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')\n",
    "    \n",
    "    # CSV report\n",
    "    csv_filename = f\"test_results_{provider_name}_{timestamp}.csv\"\n",
    "    report_gen = ReportGenerator(output_path=csv_filename)\n",
    "    report_gen.add_results(result['results'])\n",
    "    report_gen.save_csv()\n",
    "    \n",
    "    # HTML report\n",
    "    html_filename = f\"test_results_{provider_name}_{timestamp}_report.html\"\n",
    "    report_gen.save_html_report(path=html_filename, model_name=result['model'])\n",
    "    \n",
    "    print(f\"üìÑ Relat√≥rios gerados para {result['provider_name']}:\")\n",
    "    print(f\"   CSV: {csv_filename}\")\n",
    "    print(f\"   HTML: {html_filename}\")\n",
    "\n",
    "print(\"\\n‚úÖ Todos os relat√≥rios foram gerados com sucesso!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## An√°lise Detalhada por Categoria\n",
    "\n",
    "Analisamos o desempenho por arquivo e t√≠tulo das quest√µes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Detailed analysis by category\n",
    "if all_results:\n",
    "    print(\"üìä AN√ÅLISE POR CATEGORIA\")\n",
    "    print(\"=\" * 50)\n",
    "    \n",
    "    for result in all_results:\n",
    "        print(f\"\\n{result['provider_name']} ({result['model']})\")\n",
    "        print(\"-\" * 40)\n",
    "        \n",
    "        # Group by arquivo\n",
    "        by_file = {}\n",
    "        for eval_result in result['results']:\n",
    "            if eval_result.arquivo not in by_file:\n",
    "                by_file[eval_result.arquivo] = {'total': 0, 'correct': 0}\n",
    "            by_file[eval_result.arquivo]['total'] += 1\n",
    "            if eval_result.correta:\n",
    "                by_file[eval_result.arquivo]['correct'] += 1\n",
    "        \n",
    "        print(\"Por arquivo:\")\n",
    "        for arquivo, stats in by_file.items():\n",
    "            accuracy = stats['correct'] / stats['total'] if stats['total'] > 0 else 0\n",
    "            print(f\"  {arquivo}: {accuracy:.2%} ({stats['correct']}/{stats['total']})\")\n",
    "        \n",
    "        # Group by titulo\n",
    "        by_title = {}\n",
    "        for eval_result in result['results']:\n",
    "            if eval_result.titulo not in by_title:\n",
    "                by_title[eval_result.titulo] = {'total': 0, 'correct': 0}\n",
    "            by_title[eval_result.titulo]['total'] += 1\n",
    "            if eval_result.correta:\n",
    "                by_title[eval_result.titulo]['correct'] += 1\n",
    "        \n",
    "        print(\"\\nPor categoria:\")\n",
    "        for titulo, stats in sorted(by_title.items()):\n",
    "            accuracy = stats['correct'] / stats['total'] if stats['total'] > 0 else 0\n",
    "            print(f\"  {titulo}: {accuracy:.2%} ({stats['correct']}/{stats['total']})\")\n",
    "\n",
    "print(\"\\n‚úÖ An√°lise completa finalizada!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Resumo Final\n",
    "\n",
    "Sum√°rio dos testes realizados com as primeiras 20 perguntas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"üéØ RESUMO FINAL DO TESTE\")\n",
    "print(\"=\" * 50)\n",
    "print(f\"Dataset testado: Primeiras 20 perguntas do HealthBench-BR\")\n",
    "print(f\"Providers testados: {len(all_results)} de {len(active_providers)} ativos\")\n",
    "print(f\"Data/Hora: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\")\n",
    "\n",
    "if all_results:\n",
    "    print(\"\\nResultados:\")\n",
    "    for result in sorted(all_results, key=lambda x: x['accuracy'], reverse=True):\n",
    "        print(f\"  {result['provider_name']}: {result['accuracy']:.2%} ({result['correct']}/20)\")\n",
    "    \n",
    "    avg_accuracy = sum(r['accuracy'] for r in all_results) / len(all_results)\n",
    "    print(f\"\\nAcur√°cia m√©dia: {avg_accuracy:.2%}\")\n",
    "\n",
    "print(\"\\n‚ú® Teste conclu√≠do com sucesso!\")\n",
    "print(\"\\nPara executar o teste completo com todo o dataset, use:\")\n",
    "print(\"python evaluate.py --provider <provider> --model <model> --html_report\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
